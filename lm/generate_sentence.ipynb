{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent any thing that they shall be used to see\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "import os\n",
    "from random import shuffle\n",
    "from random import randint\n",
    "from random import uniform\n",
    "from math import floor\n",
    "import shutil\n",
    "import codecs\n",
    "import math\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "#brown train and test\n",
    "#TRAIN_PATH = '../data/brown/train/train_and_validate.txt'\n",
    "#TEST_PATH = '../data/brown/test/test.txt'\n",
    "\n",
    "#gutenberg train and test\n",
    "#TRAIN_PATH = '../data/gutenberg/train/train_and_validate.txt'\n",
    "#TEST_PATH = '../data/gutenberg/test/test.txt'\n",
    "\n",
    "#both train, brown test\n",
    "#TRAIN_PATH = '../data/both_train/both_train.txt'\n",
    "#TEST_PATH = '../data/brown/test/test.txt'\n",
    "\n",
    "#both train, gutenberg test\n",
    "TRAIN_PATH = '../data/both_train/both_train.txt'\n",
    "TEST_PATH = '../data/gutenberg/test/test.txt'\n",
    "\n",
    "\n",
    "class KNLM:\n",
    "    def __init__(self,order=2):\n",
    "        self.order = 2\n",
    "    \n",
    "    def set_training_data(self,train_file):\n",
    "        '''\n",
    "        reads file, tokenizes, replaces \"some\" rare words with <unk>. stores these in the instance \n",
    "        variable tokens\n",
    "        '''\n",
    "        f = codecs.open(train_file, encoding='utf-8')\n",
    "        tokens = nltk.word_tokenize(f.read())\n",
    "        f.close()\n",
    "        tokens_original = tokens\n",
    "        unigram_counter = Counter(ngrams(tokens,1))        \n",
    "        num_unk = 0\n",
    "        for i in range(len(tokens_original)):\n",
    "            if(  unigram_counter[tuple([tokens_original[i]])] < 3):\n",
    "                tokens[i] = '<unk>'\n",
    "                num_unk = num_unk + 1\n",
    "\n",
    "        self.tokens = [\"<pad>\"] + tokens\n",
    "        self.unigram_counter = Counter(ngrams(self.tokens,1))\n",
    "        self.bigram_counter = Counter(ngrams(self.tokens,2))\n",
    "        self.vocabulary = set(self.tokens)\n",
    "        self.vocabulary_list = list(self.vocabulary)\n",
    "        \n",
    "    def train(self):\n",
    "        self.unique_continuations = defaultdict(set)\n",
    "        self.unique_contexts = defaultdict(set)\n",
    "        for bigram in self.bigram_counter.keys():\n",
    "            self.unique_continuations[bigram[0]].add(bigram[1])\n",
    "            self.unique_contexts[bigram[1]].add(bigram[0])\n",
    "    \n",
    "    def get_prob_kn(self,ngram):\n",
    "        abs_discount = 0.85\n",
    "        count_input_ngram = max(self.bigram_counter[ngram] - abs_discount , 0)\n",
    "        count_context = self.unigram_counter[tuple([ngram[0]])]\n",
    "        num_unique_continuations = len(self.unique_continuations[ngram[0]])\n",
    "        num_unique_contexts = len(self.unique_continuations[ngram[1]])\n",
    "        interpolation_weight = (abs_discount / count_context) * num_unique_continuations\n",
    "        continuation_probability = num_unique_contexts / len(self.bigram_counter)\n",
    "        p_kn = (count_input_ngram / count_context) + (interpolation_weight * continuation_probability)\n",
    "        return p_kn\n",
    "    \n",
    "    def __preproc_test_input(self,tokens):\n",
    "        '''converts words not in vocab to <unk>'''\n",
    "        unk_count = 0\n",
    "        for i in range(len(tokens)):\n",
    "            if(tokens[i] not in  self.vocabulary):\n",
    "                tokens[i] = '<unk>'\n",
    "                unk_count = unk_count + 1\n",
    "        tokens = ['<pad>'] + tokens\n",
    "        return tokens\n",
    "    \n",
    "    def get_perplexity(self,test_file):\n",
    "        f = codecs.open(test_file, encoding='utf-8')\n",
    "        tokens = nltk.word_tokenize(f.read())\n",
    "        tokens = self.__preproc_test_input(tokens)\n",
    "        f.close()\n",
    "        bigrams = nltk.ngrams(tokens,2)\n",
    "        sum_log_prob = 0\n",
    "        iter_count = 0\n",
    "        for bigram in bigrams: \n",
    "            prob = math.log(self.get_prob_kn(bigram))\n",
    "            sum_log_prob = sum_log_prob + prob\n",
    "            iter_count += 1\n",
    "        return math.exp( -(1.0/len(tokens)) * sum_log_prob )\n",
    "    \n",
    "    def get_random_word(self):\n",
    "        index = randint(0,len(self.vocabulary_list)-1)\n",
    "        return kn_lm.vocabulary_list[index]\n",
    "\n",
    "    \n",
    "    def generate_text(self,num_tokens=10):\n",
    "        sentence = ['<pad>']\n",
    "        while(len(sentence) < num_tokens+1):\n",
    "            random_word = self.get_random_word()\n",
    "            if(random_word == '<unk>'):\n",
    "                continue\n",
    "            bigram = tuple(sentence[-1:] + [random_word])\n",
    "            prob_bigram = self.get_prob_kn(bigram)\n",
    "            random_number = uniform(0,1)\n",
    "            if(random_number < prob_bigram):\n",
    "                sentence = sentence + [random_word]\n",
    "        print(' '.join(sentence[1:]))\n",
    "    \n",
    "\n",
    "kn_lm = KNLM()\n",
    "\n",
    "kn_lm.set_training_data(TRAIN_PATH)\n",
    "\n",
    "kn_lm.train()\n",
    "\n",
    "#print(kn_lm.get_perplexity(TEST_PATH))\n",
    "\n",
    "kn_lm.generate_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
